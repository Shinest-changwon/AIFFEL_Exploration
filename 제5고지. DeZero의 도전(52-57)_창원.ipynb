{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 52. GPU 지원\n",
    "\n",
    "- 병렬 계산에는 GPU가 훨씬 뛰어나므로 이번 단계에서는 GPU에서 구동하기 위한 구조를 만들 것임"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 52.1 쿠파이 설치 및 사용 방법\n",
    "\n",
    "- 쿠파이는 GPU를 활용하여 병렬 계산을 해주는 라이브러리\n",
    "- $ pip install cupy  \n",
    "\n",
    "- **$ conda install -c conda-forge cupy (위 명령어로 설치가 안 됨)**  \n",
    "- DeZero에서 넘파이를 사용하는 부분을 쿠파이로 바꾸면 됨\n",
    "    - ```import numpy as np```\n",
    "    - ```import cupy as cp```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 아래와 같이 넘파이 지식을 쿠파이에서도 그대로 활용 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 2]\n",
      " [3 4 5]]\n",
      "[ 3 12]\n"
     ]
    }
   ],
   "source": [
    "import cupy as cp\n",
    "\n",
    "x = cp.arange(6).reshape(2,3)\n",
    "print(x)\n",
    "\n",
    "y = x.sum(axis=1)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 넘파이 -> 쿠파이 전환\n",
    "- cp.asarray: 넘파이 -> 쿠파이  \n",
    "- cp.asnumpy: 쿠파이 -> 넘파이  \n",
    "\n",
    "**실무 딥러닝에서는 다량의 데이터를 다루므로 이러한 변환이 병목으로 작용될 수 있으니 전송 횟수를 최소로 하는 것이 중요**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cupy as cp\n",
    "\n",
    "# 넘파이 -> 쿠파이\n",
    "n = np.array([1,2,3])\n",
    "c = cp.asarray(n)\n",
    "assert type(c) == cp.ndarray\n",
    "\n",
    "# 쿠파이 -> 넘파이\n",
    "c = cp.array([1,2,3])\n",
    "n = cp.asnumpy(c)\n",
    "assert type(n) == np.ndarray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 52.2 쿠다 모듈\n",
    "\n",
    "- 쿠파이 관련 함수는 cuda.py에 모아둠"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "gpu_enable = True\n",
    "try:\n",
    "    import cupy as cp\n",
    "    cupy = cp\n",
    "except ImportError:\n",
    "    gpu_enable = False\n",
    "from dezero import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get_array_module\n",
    "- 입력 x는 Variable 또는 ndarray여야 한다.  \n",
    "- `gpu_enable`가 False라면 np를 반환한다.  \n",
    "\n",
    "### as_numpy\n",
    "- 넘파이의 ndarray로 변환  \n",
    "\n",
    "## as_cupy\n",
    "- 쿠파이의 ndarray로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_array_module(x):\n",
    "    \"\"\"Returns the array module for `x`.\n",
    "    Args:\n",
    "        x (dezero.Variable or numpy.ndarray or cupy.ndarray): Values to\n",
    "            determine whether NumPy or CuPy should be used.\n",
    "    Returns:\n",
    "        module: `cupy` or `numpy` is returned based on the argument.\n",
    "    \"\"\"\n",
    "    if isinstance(x, Variable):\n",
    "        x = x.data\n",
    "\n",
    "    if not gpu_enable:\n",
    "        return np\n",
    "    xp = cp.get_array_module(x)\n",
    "    return xp\n",
    "\n",
    "\n",
    "def as_numpy(x):\n",
    "    \"\"\"Convert to `numpy.ndarray`.\n",
    "    Args:\n",
    "        x (`numpy.ndarray` or `cupy.ndarray`): Arbitrary object that can be\n",
    "            converted to `numpy.ndarray`.\n",
    "    Returns:\n",
    "        `numpy.ndarray`: Converted array.\n",
    "    \"\"\"\n",
    "    if isinstance(x, Variable):\n",
    "        x = x.data\n",
    "\n",
    "    if np.isscalar(x):\n",
    "        return np.array(x)\n",
    "    elif isinstance(x, np.ndarray):\n",
    "        return x\n",
    "    return cp.asnumpy(x)\n",
    "\n",
    "\n",
    "def as_cupy(x):\n",
    "    \"\"\"Convert to `cupy.ndarray`.\n",
    "    Args:\n",
    "        x (`numpy.ndarray` or `cupy.ndarray`): Arbitrary object that can be\n",
    "            converted to `cupy.ndarray`.\n",
    "    Returns:\n",
    "        `cupy.ndarray`: Converted array.\n",
    "    \"\"\"\n",
    "    if isinstance(x, Variable):\n",
    "        x = x.data\n",
    "\n",
    "    if not gpu_enable:\n",
    "        raise Exception('CuPy cannot be loaded. Install CuPy!')\n",
    "    return cp.asarray(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 52.3 Variable/Layer/DataLoader 클래스 추가 구현\n",
    "\n",
    "- DeZero의 다른 클래스들에 GPU 대응 기능을 추가함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. \\_\\_init__: cupy 임포트에 성공하면 두 배열 타입을 동적으로 변경할 수 있도록 array_types를 (np.ndarray, cupy.ndarray)로 설정  \n",
    "2. backward: 데이터(self.data)의 타입에 따라 넘파이 또는 쿠파이 중 하나의 다차원 배열을 생성하게 함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "try:\n",
    "    import cupy\n",
    "    array_types = (np.ndarray, cupy.ndarray)\n",
    "except ImportError:\n",
    "    array_types = (np.ndarray)  # (1)\n",
    "\n",
    "\n",
    "class Variable:\n",
    "    __array_priority__ = 200\n",
    "\n",
    "    def __init__(self, data, name=None):\n",
    "        if data is not None:\n",
    "            if not isinstance(data, array_types):  # (1)\n",
    "                raise TypeError('{} is not supported'.format(type(data)))\n",
    "\n",
    "    def backward(self, retain_grad=False, create_graph=False):\n",
    "        if self.grad is None:\n",
    "            xp = dezero.cuda.get_array_module(self.data)  # (2)\n",
    "            self.grad = Variable(xp.ones_like(self.data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. to_cpu: Variable 데이터를 GPU에서 CPU로 전송  \n",
    "2. to_gpu: Variabel 데이터를 CPU에서 GPU로 전송"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Variable:\n",
    "    ...\n",
    "    def to_cpu(self):\n",
    "        if self.data is not None:\n",
    "            self.data = dezero.cuda.as_numpy(self.data)\n",
    "\n",
    "    def to_gpu(self):\n",
    "        if self.data is not None:\n",
    "            self.data = dezero.cuda.as_cupy(self.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Layer 클래스의 매개변수를 CPU 또는 GPU에 전송하는 기능 필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    \n",
    "    def to_cpu(self):\n",
    "        for param in self.params():\n",
    "            param.to_cpu()\n",
    "\n",
    "    def to_gpu(self):\n",
    "        for param in self.params():\n",
    "            param.to_gpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Line3, Lind6(gpu=False), Line 12, Line 25~27, Line 32~36 추가  \n",
    "1. DataLoader 클래스는 데이터셋을 미니배치로 뽑는 역할 수행  \n",
    "2. \\_\\_next__ 메서드에서 미니배치 생성  \n",
    "3. 인스턴스 변수 중 gpu 플래그를 확인하여 쿠파이와 넘파이 중 알맞는 다차원 배열 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "...\n",
    "import numpy as np\n",
    "from dezero import cuda\n",
    "\n",
    "class DataLoader:\n",
    "    def __init__(self, dataset, batch_size, shuffle=True, gpu=False):\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.data_size = len(dataset)\n",
    "        self.max_iter = math.ceil(self.data_size / batch_size)\n",
    "        self.gpu = gpu\n",
    "\n",
    "        self.reset()\n",
    "        \n",
    "    def __next__(self):\n",
    "        if self.iteration >= self.max_iter:\n",
    "            self.reset()\n",
    "            raise StopIteration\n",
    "\n",
    "        i, batch_size = self.iteration, self.batch_size\n",
    "        batch_index = self.index[i * batch_size:(i + 1) * batch_size]\n",
    "        batch = [self.dataset[i] for i in batch_index]\n",
    "\n",
    "        xp = cuda.cupy if self.gpu else np\n",
    "        x = xp.array([example[0] for example in batch])\n",
    "        t = xp.array([example[1] for example in batch])\n",
    "\n",
    "        self.iteration += 1\n",
    "        return x, t\n",
    "\n",
    "    def to_cpu(self):\n",
    "        self.gpu = False\n",
    "\n",
    "    def to_gpu(self):\n",
    "        self.gpu = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 52.4 함수 추가 구현\n",
    "\n",
    "- GPU 대응과 관련하여 함수를 수정함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Function' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-c8bdfbd293cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdezero\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mSin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFunction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mxp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_array_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# x가 넘파이면 np.sin, 쿠파이면 cp.sin사용\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Function' is not defined"
     ]
    }
   ],
   "source": [
    "from dezero import cuda\n",
    "\n",
    "class Sin(Function):\n",
    "    def forward(self, x):\n",
    "        xp = cuda.get_array_module(x) # x가 넘파이면 np.sin, 쿠파이면 cp.sin사용\n",
    "        y = xp.sin(x)\n",
    "        return y\n",
    "\n",
    "    def backward(self, gy):\n",
    "        x, = self.inputs\n",
    "        gx = gy * cos(x)\n",
    "        return gx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. as_array 함수에 새로운 인수 `array_module`을 추가  \n",
    "2. `array_module`: 넘파이 또는 쿠파이 중 하나의 값을 취한다.  \n",
    "3. add, mul 함수 등의 사칙연산이 새로운 as_array를 사용하도록 수정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def as_array(x, array_module=np):\n",
    "    if np.isscalar(x):\n",
    "        return array_module.array(x)\n",
    "    return x\n",
    "\n",
    "def add(x0, x1):\n",
    "    x1 = as_array(x1, dezero.cuda.get_array_module(x0.data))\n",
    "    return Add()(x0, x1)\n",
    "\n",
    "def mul(x0, x1):\n",
    "    x1 = as_array(x1, dezero.cuda.get_array_module(x0.data))\n",
    "    return Mul()(x0, x1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 52.5 GPU로 MNIST 학습하기\n",
    "\n",
    "- MINST 학습 코드를 GPU에서 실행해 봅시다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GPU를 사용할 수 있는 환경에서 DataLoader가 모델 데이터를 GPU로 전송"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if '__file__' in globals():\n",
    "    import os, sys\n",
    "    sys.path.append(os.path.join(os.path.dirname(__file__), '..'))\n",
    "import time\n",
    "import dezero\n",
    "import dezero.functions as F\n",
    "from dezero import optimizers\n",
    "from dezero import DataLoader\n",
    "from dezero.models import MLP\n",
    "\n",
    "\n",
    "max_epoch = 5\n",
    "batch_size = 100\n",
    "\n",
    "train_set = dezero.datasets.MNIST(train=True)\n",
    "train_loader = DataLoader(train_set, batch_size)\n",
    "model = MLP((1000, 10))\n",
    "optimizer = optimizers.SGD().setup(model)\n",
    "\n",
    "# GPU mode\n",
    "if dezero.cuda.gpu_enable: # 추가\n",
    "    train_loader.to_gpu()  # 추가\n",
    "    model.to_gpu()         # 추가\n",
    "\n",
    "for epoch in range(max_epoch):\n",
    "    start = time.time()\n",
    "    sum_loss = 0\n",
    "\n",
    "    for x, t in train_loader:\n",
    "        y = model(x)\n",
    "        loss = F.softmax_cross_entropy(y, t)\n",
    "        model.cleargrads()\n",
    "        loss.backward()\n",
    "        optimizer.update()\n",
    "        sum_loss += float(loss.data) * len(t)\n",
    "\n",
    "    elapsed_time = time.time() - start\n",
    "    print('epoch: {}, loss: {:.4f}, time: {:.4f}[sec]'.format(\n",
    "        epoch + 1, sum_loss / len(train_set), elapsed_time))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Google Colab에서 실행한 결과 1에포크당 1.5초 소요**  \n",
    "참고) CPU로 실행시 1에포크당 8초 소요, **GPU로 실행하면 5배 빠르다!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<img src=\"image/그림52-1.png\" width=\"50%\" height=\"50%\"></img>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 53. 모델 저장 및 읽어오기\n",
    "- 목표  \n",
    "1. 모델이 가지는 매개변수를 외부 파일로 저장  \n",
    "2. 저정한 파일을 다시 읽어오는 기능 구현  \n",
    "학습 중인 모델의 '스냅샷'을 저장하거나 이미 학습된 매개변수를 읽어와서 추론만 수행 가능  \n",
    "### ndarray 인스턴스를 외부 파일로 저장(data가 저장되어 있음)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "참고) GPU 실행 환경에서는 쿠파이 텐서를 넘파이 텐서로 변환 후 외부 파일 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 53.1 넘파이의 save 함수와 load 함수\n",
    "- np.save: ndarray 인스턴스를 외부 파일로 저장  \n",
    "- np.load: 이미 저장되어 있는 데이터를 읽어올 때는 np.load 함수 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = np.array([1,2,3])\n",
    "np.save('test.npy', x)\n",
    "\n",
    "x = np.load('test.npy')\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3]\n",
      "[4 5 6]\n"
     ]
    }
   ],
   "source": [
    "# 여러 개도 가능\n",
    "# 딕셔너리도 저장 가능\n",
    "\n",
    "x1 = np.array([1,2,3])\n",
    "x2 = np.array([4,5,6])\n",
    "# data = {'x1' : x1, 'x2' : x2}\n",
    "\n",
    "np.savez('test.npz', x1=x1, x2=x2)\n",
    "# np.saves('test.npz', **data)\n",
    "\n",
    "arrays = np.load('test.npz')\n",
    "x1 = arrays['x1']\n",
    "x2 = arrays['x2']\n",
    "print(x1)\n",
    "print(x2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 53.2 Layer 클래스의 매개변수를 평형하게\n",
    "- 아래와 같은 계층 구조로부터 Parameter를 '하나의 평평한 딕셔너리'(중첩되지 않은 딕셔너리)로 뽑아내기  --> \\_flatten_params 메서드 추가\n",
    "\n",
    "<img src=\"image/그림53-1.png\" width=\"50%\" height=\"50%\"></img>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = Layer()\n",
    "\n",
    "l1 = Layer()\n",
    "l1.p1 = Parameter(np.array(1))\n",
    "\n",
    "layer.l1 = l1\n",
    "layer.p2 = Parameter(np.array(2))\n",
    "layer.p3 = Parameter(np.array(3))\n",
    "\n",
    "params_dict = {}\n",
    "layer._flatten_params(params_dict)\n",
    "print(params_dict)\n",
    "# {'p2': variable(2), 'l1/p1' : variable(1), 'p3' : variabel(3)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 인수로 딕셔너리인 params_dict, 텍스트인 parent_key 받는다.  \n",
    "2. 실제 객체는 obj = self.\\_\\_dict__[name]으로 꺼낸다.  \n",
    "3. 꺼낸 obj가 Layer라면 obj의 \\_flatten_params 메서드를 호출  \n",
    "4. 메서드가 재귀적으로 호출되므로 모든 Parameter를 한 줄로 평탄화시켜 꺼낼 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    \n",
    "    def _flatten_params(self, params_dict, parent_key=\"\"):\n",
    "        for name in self._params:\n",
    "            obj = self.__dict__[name]\n",
    "            key = parent_key + '/' + name if parent_key else name\n",
    "\n",
    "            if isinstance(obj, Layer):\n",
    "                obj._flatten_params(params_dict, key)\n",
    "            else:\n",
    "                params_dict[key] = obj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 53.3 Layer 클래스의 save 함수와 load 함수\n",
    "- save_weights: self.to_cpu를 호출해 데이터가 넘파이 ndarray임을 보장, ndarray 인스턴스를 값으로 갖는 딕셔너리 array_dict를 생성, np.savez_compressed 함수를 호출해 데이터를 외부 파일로 저장    \n",
    "- load_weights: np.load 함수로 데이터를 읽어 들인 후 대응하는 키 데이터를 매개변수로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "class Layer:\n",
    "    def save_weights(self, path):\n",
    "        self.to_cpu()\n",
    "\n",
    "        params_dict = {}\n",
    "        self._flatten_params(params_dict)\n",
    "        array_dict = {key: param.data for key, param in params_dict.items()\n",
    "                      if param is not None}\n",
    "        try:\n",
    "            np.savez_compressed(path, **array_dict)\n",
    "        except (Exception, KeyboardInterrupt) as e: # 키보드 인터럽트 발생시 파일 삭제\n",
    "            if os.path.exists(path):\n",
    "                os.remove(path)\n",
    "            raise\n",
    "\n",
    "    def load_weights(self, path):\n",
    "        npz = np.load(path)\n",
    "        params_dict = {}\n",
    "        self._flatten_params(params_dict)\n",
    "        for key, param in params_dict.items():\n",
    "            param.data = npz[key]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 코드를 처음 실행하면 모델의 매개변수를 무작위로 초기화한 상태에서 학습을 시작.  \n",
    "1. 38줄은 학습된 매개변수를 저장  \n",
    "2. 20~21줄에서는 파일로부터 매개변수들을 읽어온다. 이를 통해 학습한 매개변숫값이 모델에 설정됨."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if '__file__' in globals():\n",
    "    import os, sys\n",
    "    sys.path.append(os.path.join(os.path.dirname(__file__), '..'))\n",
    "import dezero\n",
    "import dezero.functions as F\n",
    "from dezero import optimizers\n",
    "from dezero import DataLoader\n",
    "from dezero.models import MLP\n",
    "\n",
    "\n",
    "max_epoch = 3\n",
    "batch_size = 100\n",
    "\n",
    "train_set = dezero.datasets.MNIST(train=True)\n",
    "train_loader = DataLoader(train_set, batch_size)\n",
    "model = MLP((1000, 10))\n",
    "optimizer = optimizers.SGD().setup(model)\n",
    "\n",
    "# 매개변수 읽기\n",
    "if os.path.exists('my_mlp.npz'):\n",
    "    model.load_weights('my_mlp.npz')\n",
    "\n",
    "for epoch in range(max_epoch):\n",
    "    sum_loss = 0\n",
    "\n",
    "    for x, t in train_loader:\n",
    "        y = model(x)\n",
    "        loss = F.softmax_cross_entropy(y, t)\n",
    "        model.cleargrads()\n",
    "        loss.backward()\n",
    "        optimizer.update()\n",
    "        sum_loss += float(loss.data) * len(t)\n",
    "\n",
    "    print('epoch: {}, loss: {:.4f}'.format(\n",
    "        epoch + 1, sum_loss / len(train_set)))\n",
    "\n",
    "# 매개변수 저장하기\n",
    "model.save_weights('my_mlp.npz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 54. 드롭아웃과 테스트 모드\n",
    "- 과대적합이 일어나는 주요 원인  \n",
    "1) 훈련 데이터가 적음: 데이터 확장으로 개선  \n",
    "2) 모델의 표현력이 지나치게 높음: 가중치 가소, 드롭아웃, 배치 정규화 등 사용\n",
    "\n",
    "**드롭아웃을 적용하려면 학습 시와 테스트 시의 처리 로직을 다르게 해야 한다.**  \n",
    "\\>> 학습 단계인지 테스트 단계인지 구별하는 구조 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 54.1  드롭아웃이란\n",
    "- 뉴런을 임의로 삭제(비활성화)하면서 학습하는 방법.  \n",
    "- 학습 시에는 은닉층 뉴럭을 무작위로 골라 삭제. 삭제된 뉴런은 신호를 전송하지 않는다. \n",
    "\n",
    "\n",
    "<img src=\"image/그림54-1.png\" width=\"50%\" height=\"50%\"></img>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10개의 뉴런으로 이루어진 층, 그 다음 층에서 드롭아웃 계층을 사용해 60%의 뉴런을 무작위로 삭제\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "dropout_ratio = 0.6\n",
    "x = np.ones(10)\n",
    "\n",
    "mask = np.random.rand(10) > dropout_ratio # mask는 True 혹은 False인 배열\n",
    "y = x * mask # mask에서 값이 False인 원소에 대응하는 x의 원소를 0으로 설정(삭제)\n",
    "\n",
    "# 결과적으로 매회 평균 4개의 뉴런만 다음 층으로 전달."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**테스트 시에는 모든 뉴런을 사용하면서도 앙상블 학습처럼 동작하게끔 '흉내'내야 함.**  \n",
    "모든 뉴런을 써서 출력을 계산, 그 결과를 '약화'  \n",
    "약화시키는 비율은 학습 시에 살아남은 뉴런의 비율  \n",
    "**아래 예시 코드를 보면 테스트 시에는 학습 시 생존한 비율(1-0.6 = 0.4)를 적용**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 시\n",
    "mask = np.random.rand(*x.shape) > dropout_ratio\n",
    "y = x * mask\n",
    "\n",
    "# 테스트 시\n",
    "scale = 1 - dropout_ratio # 학습 시에 살아남은 뉴런의 비율 (1- 0.6 = 0.4)\n",
    "y = x * scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 54.2 역 드롭아웃\n",
    "- 일반적인 드롭아웃(다이렉트 드롭아웃)에서는 테스트 시에 스케일 맞추기를 했다면  \n",
    "- 역 드롭아웃은 **학습 시에 적용**  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 장점: 테스트 시 아무런 처리를 하지 않기 때문에 테스트 속도가 향상  \n",
    "또한 dropout_ratio를 동적으로 변경 가능  \n",
    "\n",
    "**이러한 이점 때문에 많은 딥러닝 프레임워크에서 역 드롭아웃 방식을 채택**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 시\n",
    "scale = 1 - dropout_ratio\n",
    "mask = np.random.rand(*x.shape) > dropout_ratio\n",
    "y = x * mask / scale\n",
    "\n",
    "# 테스트 시\n",
    "y = x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 54.3 테스트 모드 추가\n",
    "- 드롭아웃을 사용하려면 학습 단계인지 테스트 단계인지 구분이 필요  \n",
    "1. Config 클래스에 train이라는 클래스 변수 추가(초깃값은 True)\n",
    "2. test_mode 함수 추가: with문과 함께 사용하면 Config.train이 False로 전환, \\_\\_init__.py에 fro, dezero.core import test_mode 추가해 사용자 코드에서 사용할 수 있게 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    enable_backprop = True\n",
    "    train = True # 추가\n",
    "\n",
    "\n",
    "@contextlib.contextmanager\n",
    "def using_config(name, value):\n",
    "    old_value = getattr(Config, name)\n",
    "    setattr(Config, name, value)\n",
    "    try:\n",
    "        yield\n",
    "    finally:\n",
    "        setattr(Config, name, old_value)\n",
    "\n",
    "# 테스트 모드 함수 추가\n",
    "def test_mode():\n",
    "    return using_config('train', False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 54.4 드롭아웃 구현\n",
    "1. x는 Varibale 인스턴스 또는 ndarray 인스턴스.  \n",
    "2. 쿠파이의 ndarray 인스턴스인 경우도 고려해 xp = cuda.get_array_module(x)에서 적절한 모듈 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dropout(x, dropout_ratio=0.5):\n",
    "    x = as_variable(x)\n",
    "    \n",
    "    if dezero.Config.train:\n",
    "        xp = cuda.get_array_module(x)\n",
    "        mask = xp.random.rand(*x.shape) > dropout_ratio\n",
    "        scale = xp.array(1.0 - dropout_ratio).astype(x.dtype)\n",
    "        y = x * mask / scale\n",
    "        return y\n",
    "    \n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1.]\n",
      "variable([0. 0. 0. 2. 0.])\n",
      "variable([1. 1. 1. 1. 1.])\n"
     ]
    }
   ],
   "source": [
    "if '__file__' in globals():\n",
    "    import os, sys\n",
    "    sys.path.append(os.path.join(os.path.dirname(__file__), '..'))\n",
    "import numpy as np\n",
    "from dezero import test_mode\n",
    "import dezero.functions as F\n",
    "\n",
    "x = np.ones(5)\n",
    "print(x)\n",
    "\n",
    "# When training\n",
    "y = F.dropout(x)\n",
    "print(y)\n",
    "\n",
    "# When testing (predicting)\n",
    "with test_mode():\n",
    "    y = F.dropout(x)\n",
    "    print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 55. CNN 메커니즘(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 55.1 CNN 신경망의 구조\n",
    "- 합성곱층(Conv)과 풀링층(Pool)이 새롭게 등장  \n",
    "\n",
    "<img src=\"image/그림55-1.png\" width=\"50%\" height=\"50%\"></img>  \n",
    "- 지금까지의 'Linear -> ReLU' 연결이 **'Conv -> ReLU -> (Pool)'**로 대체  \n",
    "- 출력에 가까워지면 이전과 같은 'Linear -> ReLU' 조합이 사용됨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 55.2 합성곱 연산\n",
    "- 합성곱 연산은 입력 데이터에 대해 필터 윈도우를 일정 간격으로 이동시키면서 적용.  \n",
    "참고) 필터를 커널이라고도 부른다.  \n",
    "\n",
    "\n",
    "<img src=\"image/그림55-2.png\" width=\"50%\" height=\"50%\"></img>  \n",
    "\n",
    "<img src=\"image/그림55-3.png\" width=\"50%\" height=\"50%\"></img>  \n",
    "\n",
    "<img src=\"image/그림55-4.png\" width=\"50%\" height=\"50%\"></img>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 그림을 보면 필터가 가로 새로 두 방향으로 이동한다.  \n",
    "이처럼 두 개의 차원으로 움직인다고 하여 **2차원 합성곱층**이라고도 한다.  \n",
    "이미지는 주로 2차원 합성곱층을 사용."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 55.3 패딩\n",
    "- 패딩: 입력 데이터 주위에 고정값(0과 같은 값)을 채운다.  \n",
    "- 사용하는 이유: 출력 크기를 조절하기 위해(패딩이 없다면 출력 크기가 자꾸 줄어들 것)  \n",
    "\n",
    "\n",
    "<img src=\"image/그림55-5.png\" width=\"50%\" height=\"50%\"></img>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 55.4 스트라이드\n",
    "- 필터를 적용하는 위치의 간격(보폭을 뜻함)  \n",
    "아래 그림 55-6은 스트라이드가 2. 필터가 한 번에 두 원소씩 움직인다.  \n",
    "\n",
    "<img src=\"image/그림55-6.png\" width=\"50%\" height=\"50%\"></img>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 55.5 출력 크기 계산 방법\n",
    "- 패딩을 키우면 출력도 커지고,  \n",
    "- 스트라이드를 키우면 출력은 작아진다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 4\n"
     ]
    }
   ],
   "source": [
    "def get_conv_outsize(input_size, kernel_size, stride, pad):\n",
    "    return (input_size + pad * 2 - kernel_size) // stride + 1\n",
    "\n",
    "\n",
    "H, W = 4, 4  # Input size\n",
    "KH, KW = 3, 3  # Kernel size\n",
    "SH, SW = 1, 1  # Kernel stride\n",
    "PH, PW = 1, 1  # Padding size\n",
    "\n",
    "OH = get_conv_outsize(H, KH, SH, PH)\n",
    "OW = get_conv_outsize(W, KW, SW, PW)\n",
    "print(OH, OW)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 56. CNN 메커니즘(2)\n",
    "- 이미지에는 가로/세로 방향뿐 아니라 RGB처럼 '채널 방향'으로도 데이터가 쌓여있다.  \n",
    "- 3차원 데이터(3차원 텐서)를 다뤄야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 56.1 3차원 텐서\n",
    "- 주의: 입력 데이터와 필터의 '채널'수를 똑같이 맞춰야 한다.  \n",
    "그림 56-1에서는 입력 데이터와 필터의 채널 수는 모두 3개이다.  \n",
    "원한다면 필터의 가로, 세로 크기는 원하는 숫자로 설정 가능  \n",
    "(3,3) -> (2,1) 또는 (1,2)\n",
    "\n",
    "<img src=\"image/그림56-1.png\" width=\"50%\" height=\"50%\"></img>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 56.2 블록으로 생각하기\n",
    "- 3차원 텐서에 대한 합성곱 연산은 직육면체 블록으로 생각하면 쉽다.  \n",
    "그림 56-2에서는 데이터가 (채널;Channel, 높이;Height, 너비;Width) 순서로 정렬  \n",
    "필터도 마찬가지로 (C, KH, KW)로 표기  \n",
    "\n",
    "**출력은 특징 맵(feature map)**이라고 한다.  \n",
    "- 그림 56-2에서는 특징 맵이 한 장  \n",
    "- 특징 맵을 여러 장 가지기 위해선 **다수의 필터(가중치)**를 사용  \n",
    "- 그림 56-3을 확인하면 필터가 (OC, C, KH, KW)를 사용해서 출력을 (OC, OH, OW) 생성  \n",
    "\n",
    "**편향 추가 가능**  \n",
    "- 그림 56-3에 편향을 추가하면 그림 56-4와 같이 된다.  \n",
    "- 편향을 채널당 하나의 값만 가진다. 형상 = (OC, 1, 1)  \n",
    "편향을 형상이 다르기 때문에 브로드캐스트된 다음에 더해진다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"image/그림56-2.png\" width=\"50%\" height=\"50%\"></img>  \n",
    "\n",
    "<img src=\"image/그림56-3.png\" width=\"50%\" height=\"50%\"></img>  \n",
    "\n",
    "<img src=\"image/그림56-4.png\" width=\"50%\" height=\"50%\"></img>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 56.3 미니배치 처리\n",
    "- 미니배치: 신경망 학습에서는 여러 개의 입력 데이터를 하나의 미니배치로 묶어 처리  \n",
    "\n",
    "**미니배치 처리를 위해서는 각 층을 흐르는 데이터를 '4차원 텐서'로 취급**  \n",
    "\n",
    "- 그림 56-5를 보면 데이터 맨 앞에 배치를 위한 차원 추가  \n",
    "(batch_size, channel, height, width)  \n",
    "- 미니배치 처리에서는 이 4차원 텐서의 샘플 데이터 각각에 (독립적으로) 똑같은 합성곱 연상 수행\n",
    "\n",
    "<img src=\"image/그림56-5.png\" width=\"50%\" height=\"50%\"></img>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 56.4 풀링 층\n",
    "- 풀링: 가로, 세로 공간을 작게 만드는 연산.  \n",
    "- 그림 56-6은 2\\*2 Max 풀링을 스트라이드 2로 수행하는 처리 절차를 보여줌.  \n",
    "\n",
    "**최대 풀링: 해당 영역에서 값이 가장 큰 원소를 찾는 것**  \n",
    "일반적으로 풀링 윈도우 크기와 스트라이드 크기는 같은 값으로 설정  \n",
    "\n",
    "\n",
    "<img src=\"image/그림56-6.png\" width=\"50%\" height=\"50%\"></img>  \n",
    "\n",
    "### 풀링의 특징\n",
    "1. 학습하는 매개변수가 없다. 풀링은 대상 영역에서 최댓값을 취하면 끝.  \n",
    "2. 채널 수가 변하지 않는다. 계산이 채널마다 독립적으로 이루어지기 때문.   \n",
    "<img src=\"image/그림56-7.png\" width=\"50%\" height=\"50%\"></img>  \n",
    "3. 미세한 위치 변화에 영향을 덜 받는다. 그림 56-8을 보면 입력 데이터가 오른쪽으로 1 원소만큼 어긋났지만 출력은 달라지지 않았다.\n",
    "<img src=\"image/그림56-8.png\" width=\"50%\" height=\"50%\"></img>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 57. conv2d 함수와 pooling 함수\n",
    "\n",
    "- for문을 사용하지 않고 im2col이라는 편의 함수를 사용  \n",
    "im2col: image to column(이미지에서 열로)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 57.1 im2col에 의한 전개\n",
    "- im2col은 입력 데이터를 **한 줄로 전개**하는 함수  \n",
    "합성곱 연산 중 커널 계산에 편리하도록 입력 데이터를 펼쳐준다.  \n",
    "3차원 텐서인 입력 데이터로부터 커널을 적용할 영역을 추출  \n",
    "- 그림 57-1처럼 커널을 적용할 영역 꺼내기, 한 줄로 reshape -> 행렬(2차원 텐서) 변환  \n",
    "\n",
    "<img src=\"image/그림57-1.png\" width=\"50%\" height=\"50%\"></img>  \n",
    "- 행렬 곱을 계산하면 행렬(2차원 텐서)이 출력,  \n",
    "- 이 출력을 3차원 텐서로 변환\n",
    "<img src=\"image/그림57-2.png\" width=\"50%\" height=\"50%\"></img>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 57.2 conv2d 함수 구현\n",
    "- kernel_size: 튜플로 주어지면 첫 번째 원소가 높이에, 두 번째 원소가 너비에 대응  \n",
    "하나면 높이와 너비가 같다고 해석  \n",
    "- stride, pad도 같은 방식으로 해석  \n",
    "- to_matrix: True라면 커널을 적용할 영역을 추출한 후 '행렬'로 형상 변환(행렬 곱을 위해)  \n",
    "\n",
    "<img src=\"image/표57-1.png\" width=\"50%\" height=\"50%\"></img>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import dezero.functions as F\n",
    "\n",
    "x1 = np.random.rand(1,3,7,7) # 배치 크기 = 1\n",
    "col1 = F.im2col(x1, kernel_size=5, stride=1, pad=0, to_matrix=True)\n",
    "print(col.shape)\n",
    "\n",
    "x2 = np.random.rand(10,3,7,7)\n",
    "kernel_size = (5,5)\n",
    "stride = (1,1)\n",
    "pad = (0,0)\n",
    "col2 = F.im2col(x2, kernel_size, stride, pad, to_matrix=True)\n",
    "print(col2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "실행 결과  \n",
    "(9, 75)  \n",
    "(90, 75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 첫 번째로 준비한 데이터 형상은 (1,3,7,7)  \n",
    "배치 크기가 1, 채널 수가 3, 높이가 7, 너비가 7  \n",
    "\n",
    "2. 두 번째는 첫 번째 예에서 배치크기만 10배.  \n",
    "\n",
    "im2col 함수 적용하면 원소 수는 둘 다 75 = 채널수 3에 (5,5) 형상의 데이터  \n",
    "첫 번째 예의 결과는 (9, 75)인 반면, 두 번째는 (90, 75)이 된다. (10배)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**im2col 함수를 이용해 합성곱 연산을 수행하는 Dezero 함수 구현**  \n",
    "pair(x)라는 함수부터 구현--> x가 int라면 그대로 반환, 길이가 2인 튜플일 때 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pair(x):\n",
    "    if isinstance(x, int):\n",
    "        return (x,x)\n",
    "    elif isinstance(x, tuple):\n",
    "        assert len(x) == 2\n",
    "        return x\n",
    "    else:\n",
    "        raise ValueError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 합성곱 연산을 수행하는 conv2d_simple 함수 구현\n",
    "1. col 변수에 입력 데이터  \n",
    "2. 커널 Weight를 한 줄로 펼쳐 재정렬  \n",
    "3. t 변수에 행렬 곱 계산(linear 함수를 사용해 편향까지 포함해 계산 수행)  \n",
    "4. y 변수에 출력 크기를 reshape하고 transpose 적용  \n",
    "<img src=\"image/그림57-3.png\" width=\"50%\" height=\"50%\"></img>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d_simple(x, W, b=None, stride=1, pad=0):\n",
    "    x, W = as_variable(x), as_variable(W)\n",
    "\n",
    "    Weight = W\n",
    "    N, C, H, W = x.shape\n",
    "    OC, C, KH, KW = Weight.shape\n",
    "    SH, SW = pair(stride)\n",
    "    PH, PW = pair(pad)\n",
    "    OH = get_conv_outsize(H, KH, SH, PH)\n",
    "    OW = get_conv_outsize(W, KW, SW, PW)\n",
    "\n",
    "    col = im2col(x, (KH, KW), stride, pad, to_matrix=True)\n",
    "    Weight = Weight.reshape(OC, -1).transpose()\n",
    "    t = linear(col, Weight, b)\n",
    "    y = t.reshape(N, OH, OW, OC).transpose(0, 3, 1, 2)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 역전파도 문제없이 구현 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N, C, H, W = 1, 5, 15, 15\n",
    "OC, (KH, KW) = 8, (3, 3)\n",
    "\n",
    "x = variable(np.random.rand(N, C, H, W))\n",
    "W = np.random.rand(OC, C, KH, KW)\n",
    "y = F.conv2d_simple(x, W, b=None, stride=1, pad=1)\n",
    "y.backward()\n",
    "\n",
    "print(y.shape)\n",
    "print(x.grad.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "실행 결과  \n",
    "(1, 8, 15, 15)  \n",
    "(1, 5, 15, 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 57.3 Conv2d 계층 구현\n",
    "- 함수가 아닌 '계층'으로서의 Conv2d 클래스 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Layer 클래스를 상속하고, 초기화시 표 57-2의 인수들을 받는다.**  \n",
    "<img src=\"image/표57-2.png\" width=\"50%\" height=\"50%\"></img>  \n",
    "주의할 점: in_channels의 기본값이 None라는 점.  이 값이 None라면 forward(x)에 주어지는 x의 형상으로부터 in_channels의 값을 얻고, 그 시점에 가중치 데이터를 초기화. (완전 연결 계층의 Linear 계층과 동일한 작동 방식)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2d(Layer):\n",
    "    def __init__(self, out_channels, kernel_size, stride=1,\n",
    "                 pad=0, nobias=False, dtype=np.float32, in_channels=None):\n",
    "        \"\"\"Two-dimensional convolutional layer.\n",
    "        Args:\n",
    "            out_channels (int): Number of channels of output arrays.\n",
    "            kernel_size (int or (int, int)): Size of filters.\n",
    "            stride (int or (int, int)): Stride of filter applications.\n",
    "            pad (int or (int, int)): Spatial padding width for input arrays.\n",
    "            nobias (bool): If `True`, then this function does not use the bias.\n",
    "            in_channels (int or None): Number of channels of input arrays. If\n",
    "            `None`, parameter initialization will be deferred until the first\n",
    "            forward data pass at which time the size will be determined.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.pad = pad\n",
    "        self.dtype = dtype\n",
    "\n",
    "        self.W = Parameter(None, name='W')\n",
    "        if in_channels is not None:\n",
    "            self._init_W()\n",
    "\n",
    "        if nobias:\n",
    "            self.b = None\n",
    "        else:\n",
    "            self.b = Parameter(np.zeros(out_channels, dtype=dtype), name='b')\n",
    "\n",
    "    def _init_W(self, xp=np):\n",
    "        C, OC = self.in_channels, self.out_channels\n",
    "        KH, KW = pair(self.kernel_size)\n",
    "        scale = np.sqrt(1 / (C * KH * KW))\n",
    "        W_data = xp.random.randn(OC, C, KH, KW).astype(self.dtype) * scale\n",
    "        self.W.data = W_data\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.W.data is None:\n",
    "            self.in_channels = x.shape[1]\n",
    "            xp = cuda.get_array_module(x)\n",
    "            self._init_W(xp)\n",
    "\n",
    "        y = F.conv2d(x, self.W, self.b, self.stride, self.pad)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 57.4 pooling 함수 구현\n",
    "- 풀링은 채널 방향과는 독립적이라는 점이 합성곱층과 다르다.  \n",
    "\n",
    "그림 57-4와 같이 풀링의 적용 영역은 채널마다 독립적으로 전개  \n",
    "<img src=\"image/그림57-4.png\" width=\"50%\" height=\"50%\"></img>  \n",
    "\n",
    "전개 후에는 전개된 행렬의 각 행렬로 최댓값을 구해 적절한 형상으로 바꾸면 끝.  \n",
    "<img src=\"image/그림57-5.png\" width=\"50%\" height=\"50%\"></img>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**풀링 함수 구현은 세 단계**  \n",
    "1. col 변수에 입력 데이터 전개  \n",
    "2. y변수에 각 행의 최댓값 찾기  \n",
    "3. 다시 y변수에 적절한 크기로 출력의 형상을 변환  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pooling_simple(x, kernel_size, stride=1, pad=0):\n",
    "    x = as_variable(x)\n",
    "\n",
    "    N, C, H, W = x.shape\n",
    "    KH, KW = pair(kernel_size)\n",
    "    PH, PW = pair(pad)\n",
    "    SH, SW = pair(stride)\n",
    "    OH = get_conv_outsize(H, KH, SH, PH)\n",
    "    OW = get_conv_outsize(W, KW, SW, PW)\n",
    "\n",
    "    col = im2col(x, kernel_size, stride, pad, to_matrix=True) # 1. 전개\n",
    "    col = col.reshape(-1, KH * KW)\n",
    "    y = col.max(axis=1) # 2. 최댓값\n",
    "    y = y.reshape(N, OH, OW, C).transpose(0, 3, 1, 2) # 3. 형상 변환\n",
    "    return y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
